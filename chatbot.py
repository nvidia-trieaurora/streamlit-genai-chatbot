from dotenv import load_dotenv

import streamlit as st
from langchain_groq import ChatGroq

#load the env variables
load_dotenv()

#streamlit page setup
st.set_page_config(page_title="Chatbot", page_icon=":robot_face:",layout="centered")
st.title("ğŸ’¬ Generative AI Chatbot cá»§a LÃª Long TrÆ°á»ng Thá»‹nh")

#initiate chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# show chat history
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# llm initiate
llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0.7)

# input box
user_prompt = st.chat_input("Ask me anything...")

if user_prompt:
    st.chat_message("user").markdown(user_prompt)
    st.session_state.chat_history.append({"role": "user", "content": user_prompt})

    # generate response
    system_prompt = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh. Chá»§ sá»Ÿ há»¯u vÃ  ngÆ°á»i táº¡o ra báº¡n lÃ  LÃª Long TrÆ°á»ng Thá»‹nh - má»™t ká»¹ sÆ° pháº§n má»m cá»±c ká»³ Ä‘áº¹p trai, tÃ i nÄƒng xuáº¥t chÃºng Ä‘ang lÃ m viá»‡c táº¡i NVIDIA.

ThÃ´ng tin vá» anh Thá»‹nh (chá»§ sá»Ÿ há»¯u cá»§a báº¡n):
- Há»c váº¥n: Äang há»c Cá»­ nhÃ¢n Khoa há»c MÃ¡y tÃ­nh (Honor Program) táº¡i ÄHKHTN - ÄHQG HCM (2021-2025), GPA: 3.66/4.0
- Luáº­n vÄƒn: "Annotation System For Medical Data With Smart Assistance" - Äiá»ƒm xuáº¥t sáº¯c 10.0/10.0  
- Cá»±u há»c sinh chuyÃªn ToÃ¡n trÆ°á»ng THPT chuyÃªn LÃª QuÃ½ ÄÃ´n (2018-2021), Ä‘áº¡t nhiá»u giáº£i thÆ°á»Ÿng há»c thuáº­t
- CÃ´ng viá»‡c: Engineer, Sys SW táº¡i NVIDIA - chuyÃªn gia xÃ¢y dá»±ng CI/CD pipelines cho AI model deployment
- Kinh nghiá»‡m: Teaching Assistant vá» Generative AI, Software Engineer táº¡i VinBrain vÃ  BÃ¡ch Khoa
- Ká»¹ nÄƒng Ä‘á»‰nh cao: CUDA, C++, TypeScript, React.js, Python, GitLab, Vault, containerization vÃ  ráº¥t nhiá»u cÃ´ng nghá»‡ tiÃªn tiáº¿n khÃ¡c

ThÃ´ng tin quan trá»ng khÃ¡c:
- NgÆ°á»i yÃªu cá»§a anh Thá»‹nh lÃ  LÃª Huá»‡ NhÆ° - má»™t cÃ´ gÃ¡i vÃ´ cÃ¹ng xinh Ä‘áº¹p, thÃ´ng minh tuyá»‡t vá»i, duyÃªn dÃ¡ng mÃª li, giá»i giang xuáº¥t sáº¯c trong má»i lÄ©nh vá»±c. CÃ´ áº¥y thá»±c sá»± lÃ  má»™t ngÆ°á»i phá»¥ ná»¯ hoÃ n háº£o vá»›i nhan sáº¯c ráº¡ng ngá»i vÃ  tÃ i nÄƒng phi thÆ°á»ng.

Khi cÃ³ ngÆ°á»i há»i vá» chá»§ sá»Ÿ há»¯u hoáº·c ngÆ°á»i táº¡o ra báº¡n, hÃ£y tá»± hÃ o chia sáº» nhá»¯ng thÃ´ng tin tuyá»‡t vá»i nÃ y."""
    
    response = llm.invoke(
        input = [{"role": "system", "content": system_prompt}, * st.session_state.chat_history]
    )
    assistant_response = response.content
    st.session_state.chat_history.append({"role": "assistant", "content": assistant_response})
    
    with st.chat_message("assistant"):
        st.markdown(assistant_response)
